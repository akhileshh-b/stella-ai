{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:24:27.476443Z",
     "iopub.status.busy": "2025-03-27T21:24:27.475990Z",
     "iopub.status.idle": "2025-03-27T21:24:34.432023Z",
     "shell.execute_reply": "2025-03-27T21:24:34.431346Z",
     "shell.execute_reply.started": "2025-03-27T21:24:27.476400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import bitsandbytes\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    dataset = [{\"input_text\": d['Context'], \"target_text\": d['Response']} for d in data]\n",
    "    return dataset\n",
    "\n",
    "data = load_data('/kaggle/input/combined-dataset/combined_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:24:34.433452Z",
     "iopub.status.busy": "2025-03-27T21:24:34.432933Z",
     "iopub.status.idle": "2025-03-27T21:24:34.496361Z",
     "shell.execute_reply": "2025-03-27T21:24:34.495417Z",
     "shell.execute_reply.started": "2025-03-27T21:24:34.433427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Loaded: 3160 Training Samples, 352 Validation Samples\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_text\": [d['input_text'] for d in train_data],\n",
    "    \"target_text\": [d['target_text'] for d in train_data]\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_text\": [d['input_text'] for d in val_data],\n",
    "    \"target_text\": [d['target_text'] for d in val_data]\n",
    "})\n",
    "\n",
    "print(f\"✅ Data Loaded: {len(train_dataset)} Training Samples, {len(val_dataset)} Validation Samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:24:34.497771Z",
     "iopub.status.busy": "2025-03-27T21:24:34.497505Z",
     "iopub.status.idle": "2025-03-27T21:24:37.849156Z",
     "shell.execute_reply": "2025-03-27T21:24:37.848310Z",
     "shell.execute_reply.started": "2025-03-27T21:24:34.497749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:24:37.850775Z",
     "iopub.status.busy": "2025-03-27T21:24:37.850441Z",
     "iopub.status.idle": "2025-03-27T21:25:04.403760Z",
     "shell.execute_reply": "2025-03-27T21:25:04.402883Z",
     "shell.execute_reply.started": "2025-03-27T21:24:37.850741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully logged in to Hugging Face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbdcf58b505480a8da049ab86ea64b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93d0b523c314c6493c37c7593adfd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fd1affbeb9476ebebb1f75a63752da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9781665edccf4739867b6fb7d0dc1c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c92a7cfcb614431a4e87d20045647ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8bd58f7f6c4e32a88affcd21b35db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and tokenizer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Perform login\n",
    "hf_token = \"token\"\n",
    "login(token=hf_token)\n",
    "print(\"✅ Successfully logged in to Hugging Face\")\n",
    "\n",
    "# Configure 4-bit quantization using BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for better GPU performance\n",
    "    bnb_4bit_use_double_quant=True,        # Enables double quantization for memory savings\n",
    "    bnb_4bit_quant_type=\"nf4\"              # Normal Float 4 (NF4) for optimal precision\n",
    ")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta/llama3.2', token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained('meta/llama3.2', device_map='auto', quantization_config=quantization_config, token=hf_token)\n",
    "\n",
    "print(\"✅ Model and tokenizer loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:25:09.118616Z",
     "iopub.status.busy": "2025-03-27T21:25:09.118245Z",
     "iopub.status.idle": "2025-03-27T21:25:09.194098Z",
     "shell.execute_reply": "2025-03-27T21:25:09.193324Z",
     "shell.execute_reply.started": "2025-03-27T21:25:09.118585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,843,200 || all params: 2,508,015,616 || trainable%: 0.0735\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Configure and apply LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:26:11.849531Z",
     "iopub.status.busy": "2025-03-27T21:26:11.849197Z",
     "iopub.status.idle": "2025-03-27T21:26:14.161685Z",
     "shell.execute_reply": "2025-03-27T21:26:14.160992Z",
     "shell.execute_reply.started": "2025-03-27T21:26:11.849505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ec6b6ae2fb4d8680d6ecdaee5c37a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbdf509e85424b930b1b3664153cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/352 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples['input_text'], max_length=256, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples['target_text'], max_length=256, truncation=True, padding=\"max_length\")\n",
    "    inputs['labels'] = targets['input_ids']\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Apply tokenization using map\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "print(\"✅ Tokenization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:26:16.534724Z",
     "iopub.status.busy": "2025-03-27T21:26:16.534401Z",
     "iopub.status.idle": "2025-03-27T21:26:16.540368Z",
     "shell.execute_reply": "2025-03-27T21:26:16.539643Z",
     "shell.execute_reply.started": "2025-03-27T21:26:16.534700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 3160\n",
      "Validation dataset size: 352\n",
      "Model loaded: True\n",
      "Tokenizer loaded: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(\"Model loaded:\", model is not None)\n",
    "print(\"Tokenizer loaded:\", tokenizer is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:27:41.426405Z",
     "iopub.status.busy": "2025-03-27T21:27:41.426046Z",
     "iopub.status.idle": "2025-03-27T21:27:41.452928Z",
     "shell.execute_reply": "2025-03-27T21:27:41.452249Z",
     "shell.execute_reply.started": "2025-03-27T21:27:41.426372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\"  # Disable wandb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:27:52.330553Z",
     "iopub.status.busy": "2025-03-27T21:27:52.330224Z",
     "iopub.status.idle": "2025-03-27T21:27:52.341864Z",
     "shell.execute_reply": "2025-03-27T21:27:52.341159Z",
     "shell.execute_reply.started": "2025-03-27T21:27:52.330526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Use a data collator to batch data correctly\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:27:57.763572Z",
     "iopub.status.busy": "2025-03-27T21:27:57.763237Z",
     "iopub.status.idle": "2025-03-27T22:38:36.645508Z",
     "shell.execute_reply": "2025-03-27T22:38:36.644742Z",
     "shell.execute_reply.started": "2025-03-27T21:27:57.763544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2370/2370 1:10:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.574300</td>\n",
       "      <td>9.733069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.137300</td>\n",
       "      <td>9.168477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.045700</td>\n",
       "      <td>8.987385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2370, training_loss=9.649729488066983, metrics={'train_runtime': 4238.5693, 'train_samples_per_second': 2.237, 'train_steps_per_second': 0.559, 'total_flos': 2.888561326030848e+16, 'train_loss': 9.649729488066983, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T22:38:45.911392Z",
     "iopub.status.busy": "2025-03-27T22:38:45.911049Z",
     "iopub.status.idle": "2025-03-27T22:38:46.626694Z",
     "shell.execute_reply": "2025-03-27T22:38:46.625845Z",
     "shell.execute_reply.started": "2025-03-27T22:38:45.911326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save Model\n",
    "trainer.save_model('./fine_tuned_llama3.2')\n",
    "tokenizer.save_pretrained('./fine_tuned_llama3.2')\n",
    "print(\"✅ Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T22:39:51.864703Z",
     "iopub.status.busy": "2025-03-27T22:39:51.864371Z",
     "iopub.status.idle": "2025-03-27T22:39:52.573379Z",
     "shell.execute_reply": "2025-03-27T22:39:52.572564Z",
     "shell.execute_reply.started": "2025-03-27T22:39:51.864676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./stella_model/tokenizer_config.json',\n",
       " './stella_model/special_tokens_map.json',\n",
       " './stella_model/tokenizer.model',\n",
       " './stella_model/added_tokens.json',\n",
       " './stella_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./stella_model\")\n",
    "tokenizer.save_pretrained(\"./stella_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T22:40:00.906580Z",
     "iopub.status.busy": "2025-03-27T22:40:00.906122Z",
     "iopub.status.idle": "2025-03-27T22:40:02.706474Z",
     "shell.execute_reply": "2025-03-27T22:40:02.705475Z",
     "shell.execute_reply.started": "2025-03-27T22:40:00.906543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./stella_model/\n",
      "./stella_model/adapter_model.safetensors\n",
      "./stella_model/training_args.bin\n",
      "./stella_model/tokenizer.json\n",
      "./stella_model/adapter_config.json\n",
      "./stella_model/tokenizer_config.json\n",
      "./stella_model/special_tokens_map.json\n",
      "./stella_model/tokenizer.model\n",
      "./stella_model/README.md\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf stella_model.tar.gz ./stella_model\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6984936,
     "sourceId": 11189026,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
